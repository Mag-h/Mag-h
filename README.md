# ğŸ‘‹ Hi, Iâ€™m Maguelonne HÃ©ritier  



I am a **Computer Vision and Machine Learning Lead** with 20+ years of experience in **AI research and industry**.  

My career is dedicated to designing **responsible AI systems** that are interpretable, reliable, and impactful â€” particularly in **critical security applications**.  



---



## ğŸ” Current Focus  

- **Physical security & video surveillance systems**: designing AI that operates in high-stakes, mission-critical contexts  

- **Responsible AI**: embedding interpretability and transparency into models by design  

- **Embedded analytics**: developing efficient deep learning solutions for constrained hardware, ensuring performance under strict resource limitations  

- **Reliability first**: delivering models that meet industrial requirements for robustness, safety, and trustworthiness  



---



## ğŸ† Highlights  

- Lead R&D in **AI for physical security** at Genetec (2017â€“present)  

- Expertise in **interpretable and trustworthy AI** for surveillance systems, where accountability is essential  

- Patents and publications bridging **academic research and industrial R&D**  

- Former specialist at Matrox, designing patented computer vision algorithms  

- Senior Research Engineer at CRIM â€“ *1st place at TRECVID 2009 Video Copy Detection Challenge*  



---



## ğŸ“š Selected Publications  

- **EXaM**: Concept-based representation learning for explainability â€“ *CVPR Workshop 2025* (Spotlight)  

- **CenterPoly**: Real-time instance segmentation â€“ *ICCV 2021*  

- **RN-VID**: Video object detection â€“ *ICIAR 2020, Best Paper*  

â¡ï¸ [See full list on Google Scholar](https://scholar.google.com)  



---



## ğŸŒ Why Responsible AI Matters  

In critical applications like physical security, AI is not just about accuracy â€” itâ€™s about **trust, transparency, and accountability**.  

I believe that **interpretable by design models** are the path to building systems that people can understand, rely on, and responsibly deploy in society.  



---



ğŸ“« [LinkedIn](https://www.linkedin.com/in/your-profile) | [Google Scholar](https://scholar.google.com)  

# ğŸ‘‹ Hi, Iâ€™m Maguelonne HÃ©ritier  


I am a **Computer Vision and Machine Learning Lead** with 15+ years of experience in **AI research and industry**.  

My career is dedicated to designing **responsible AI systems** that are interpretable, reliable, and impactful â€” particularly in **critical security applications**.  



---



## ğŸ” Current Focus  

- **Physical security & video surveillance systems**: designing AI that operates in high-stakes, mission-critical contexts  

- **Responsible AI**: embedding interpretability and transparency into models by design  

- **Embedded analytics**: developing efficient deep learning solutions for constrained hardware, ensuring performance under strict resource limitations  

- **Reliability first**: delivering models that meet industrial requirements for robustness, safety, and trustworthiness  



---



## ğŸ† Highlights  

- Lead R&D in **AI for physical security** at Genetec (2017â€“present)  

- Expertise in **interpretable and trustworthy AI** for surveillance systems, where accountability is essential  

- Patents and publications bridging **academic research and industrial R&D**  

- Former specialist at Matrox, designing patented computer vision algorithms  

- Senior Research Engineer at CRIM â€“ *1st place at TRECVID 2009 Video Copy Detection Challenge*  



---



## ğŸ“š Selected Publications  

- **EXaM**: Concept-based representation learning for explainability â€“ *CVPR Workshop 2025* (Spotlight)  

- **CenterPoly**: Real-time instance segmentation â€“ *ICCV 2021*  

- **RN-VID**: Video object detection â€“ *ICIAR 2020, Best Paper*  

â¡ï¸ [See full list on Google Scholar](https://scholar.google.com)  



---



## ğŸŒ Why Responsible AI Matters  

In critical applications like physical security, AI is not just about accuracy â€” itâ€™s about **trust, transparency, and accountability**.  

I believe that **interpretable by design models** are the path to building systems that people can understand, rely on, and responsibly deploy in society.  



---



ğŸ“« [LinkedIn](https://www.linkedin.com/in/your-profile) | [Google Scholar](https://scholar.google.com)  
